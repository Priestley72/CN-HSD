{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04,
      "grad_norm": 3.4010815620422363,
      "learning_rate": 4.5e-06,
      "loss": 1.8411,
      "step": 10
    },
    {
      "epoch": 0.08,
      "grad_norm": 4.044638633728027,
      "learning_rate": 9.5e-06,
      "loss": 1.7431,
      "step": 20
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.753086805343628,
      "learning_rate": 1.45e-05,
      "loss": 1.5176,
      "step": 30
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.0779194831848145,
      "learning_rate": 1.9500000000000003e-05,
      "loss": 1.1083,
      "step": 40
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.4277507066726685,
      "learning_rate": 2.45e-05,
      "loss": 0.8466,
      "step": 50
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.9435792565345764,
      "learning_rate": 2.95e-05,
      "loss": 0.5346,
      "step": 60
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6196565628051758,
      "learning_rate": 3.45e-05,
      "loss": 0.3819,
      "step": 70
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5598791837692261,
      "learning_rate": 3.9500000000000005e-05,
      "loss": 0.3574,
      "step": 80
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.8321451544761658,
      "learning_rate": 4.4500000000000004e-05,
      "loss": 0.3156,
      "step": 90
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6920554041862488,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 0.3296,
      "step": 100
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5177592039108276,
      "learning_rate": 4.9997231914115064e-05,
      "loss": 0.2648,
      "step": 110
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.894072949886322,
      "learning_rate": 4.998766400914329e-05,
      "loss": 0.3199,
      "step": 120
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5393140912055969,
      "learning_rate": 4.99712647263317e-05,
      "loss": 0.2689,
      "step": 130
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.583259642124176,
      "learning_rate": 4.9948038549080456e-05,
      "loss": 0.2944,
      "step": 140
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6444565057754517,
      "learning_rate": 4.991799182719451e-05,
      "loss": 0.2615,
      "step": 150
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5869633555412292,
      "learning_rate": 4.988113277514761e-05,
      "loss": 0.2438,
      "step": 160
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.6231038570404053,
      "learning_rate": 4.983747146983656e-05,
      "loss": 0.2519,
      "step": 170
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.6898152828216553,
      "learning_rate": 4.978701984782625e-05,
      "loss": 0.2567,
      "step": 180
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.7255253791809082,
      "learning_rate": 4.9729791702086414e-05,
      "loss": 0.2665,
      "step": 190
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.7149105072021484,
      "learning_rate": 4.966580267822065e-05,
      "loss": 0.2583,
      "step": 200
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6853536367416382,
      "learning_rate": 4.959507027018918e-05,
      "loss": 0.2833,
      "step": 210
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.0017062425613403,
      "learning_rate": 4.951761381552609e-05,
      "loss": 0.2402,
      "step": 220
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.7655638456344604,
      "learning_rate": 4.9433454490052675e-05,
      "loss": 0.2831,
      "step": 230
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.5288293957710266,
      "learning_rate": 4.934261530208823e-05,
      "loss": 0.2372,
      "step": 240
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.6259792447090149,
      "learning_rate": 4.9245121086159674e-05,
      "loss": 0.2328,
      "step": 250
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.7580963969230652,
      "learning_rate": 4.91409984962122e-05,
      "loss": 0.22,
      "step": 260
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.700571596622467,
      "learning_rate": 4.903027599832223e-05,
      "loss": 0.2288,
      "step": 270
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.6093140244483948,
      "learning_rate": 4.891298386291513e-05,
      "loss": 0.2268,
      "step": 280
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.7652996182441711,
      "learning_rate": 4.878915415648957e-05,
      "loss": 0.2026,
      "step": 290
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.7421311736106873,
      "learning_rate": 4.865882073285086e-05,
      "loss": 0.2369,
      "step": 300
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.718757152557373,
      "learning_rate": 4.852201922385564e-05,
      "loss": 0.245,
      "step": 310
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.6188741326332092,
      "learning_rate": 4.837878702967052e-05,
      "loss": 0.2299,
      "step": 320
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.6996829509735107,
      "learning_rate": 4.822916330854722e-05,
      "loss": 0.2176,
      "step": 330
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.6946936249732971,
      "learning_rate": 4.8073188966117126e-05,
      "loss": 0.2155,
      "step": 340
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.7642903923988342,
      "learning_rate": 4.7910906644208054e-05,
      "loss": 0.2354,
      "step": 350
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.564271092414856,
      "learning_rate": 4.774236070918643e-05,
      "loss": 0.2026,
      "step": 360
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.7307180166244507,
      "learning_rate": 4.7567597239827974e-05,
      "loss": 0.2077,
      "step": 370
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.759310245513916,
      "learning_rate": 4.738666401472022e-05,
      "loss": 0.199,
      "step": 380
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.8666402697563171,
      "learning_rate": 4.719961049920027e-05,
      "loss": 0.2033,
      "step": 390
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.7304611802101135,
      "learning_rate": 4.700648783183159e-05,
      "loss": 0.2206,
      "step": 400
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 0.682550311088562,
      "learning_rate": 4.68073488104231e-05,
      "loss": 0.2062,
      "step": 410
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.7621251344680786,
      "learning_rate": 4.660224787759486e-05,
      "loss": 0.238,
      "step": 420
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.8188163638114929,
      "learning_rate": 4.639124110589399e-05,
      "loss": 0.233,
      "step": 430
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.7436081767082214,
      "learning_rate": 4.617438618246498e-05,
      "loss": 0.2068,
      "step": 440
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.6030694246292114,
      "learning_rate": 4.595174239327862e-05,
      "loss": 0.2113,
      "step": 450
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.9208034873008728,
      "learning_rate": 4.572337060692379e-05,
      "loss": 0.2029,
      "step": 460
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.6734431385993958,
      "learning_rate": 4.548933325796658e-05,
      "loss": 0.2249,
      "step": 470
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.5946890115737915,
      "learning_rate": 4.524969432988138e-05,
      "loss": 0.2102,
      "step": 480
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.706053614616394,
      "learning_rate": 4.500451933755833e-05,
      "loss": 0.209,
      "step": 490
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.7283616662025452,
      "learning_rate": 4.4753875309392266e-05,
      "loss": 0.198,
      "step": 500
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.9037328362464905,
      "learning_rate": 4.449783076895783e-05,
      "loss": 0.2213,
      "step": 510
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.6568022966384888,
      "learning_rate": 4.42364557162758e-05,
      "loss": 0.177,
      "step": 520
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.6384022235870361,
      "learning_rate": 4.396982160867575e-05,
      "loss": 0.1806,
      "step": 530
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.5939745306968689,
      "learning_rate": 4.369800134126039e-05,
      "loss": 0.1625,
      "step": 540
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.7603384852409363,
      "learning_rate": 4.342106922697669e-05,
      "loss": 0.1542,
      "step": 550
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.9330316185951233,
      "learning_rate": 4.313910097629959e-05,
      "loss": 0.1712,
      "step": 560
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 0.8394843935966492,
      "learning_rate": 4.2852173676533356e-05,
      "loss": 0.1423,
      "step": 570
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.8042389154434204,
      "learning_rate": 4.256036577073681e-05,
      "loss": 0.1566,
      "step": 580
    },
    {
      "epoch": 2.36,
      "grad_norm": 1.0200955867767334,
      "learning_rate": 4.2263757036277705e-05,
      "loss": 0.1834,
      "step": 590
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.7658078670501709,
      "learning_rate": 4.1962428563022414e-05,
      "loss": 0.1545,
      "step": 600
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.7451701760292053,
      "learning_rate": 4.165646273116681e-05,
      "loss": 0.159,
      "step": 610
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.801264762878418,
      "learning_rate": 4.134594318871423e-05,
      "loss": 0.1575,
      "step": 620
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.9007186889648438,
      "learning_rate": 4.1030954828607095e-05,
      "loss": 0.1621,
      "step": 630
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.7783108949661255,
      "learning_rate": 4.07115837655179e-05,
      "loss": 0.1683,
      "step": 640
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.984932005405426,
      "learning_rate": 4.0387917312306414e-05,
      "loss": 0.1604,
      "step": 650
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.9246861338615417,
      "learning_rate": 4.006004395614913e-05,
      "loss": 0.1825,
      "step": 660
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.7629042863845825,
      "learning_rate": 3.972805333434784e-05,
      "loss": 0.1587,
      "step": 670
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.844980776309967,
      "learning_rate": 3.9392036209823644e-05,
      "loss": 0.1542,
      "step": 680
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.8830378651618958,
      "learning_rate": 3.905208444630327e-05,
      "loss": 0.191,
      "step": 690
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.8382434248924255,
      "learning_rate": 3.870829098320446e-05,
      "loss": 0.1643,
      "step": 700
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.8955271244049072,
      "learning_rate": 3.8360749810227286e-05,
      "loss": 0.1472,
      "step": 710
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.922419011592865,
      "learning_rate": 3.800955594165825e-05,
      "loss": 0.1454,
      "step": 720
    },
    {
      "epoch": 2.92,
      "grad_norm": 1.0964257717132568,
      "learning_rate": 3.7654805390394366e-05,
      "loss": 0.1637,
      "step": 730
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.9427591562271118,
      "learning_rate": 3.72965951416942e-05,
      "loss": 0.1651,
      "step": 740
    },
    {
      "epoch": 3.0,
      "grad_norm": 1.1677213907241821,
      "learning_rate": 3.693502312666304e-05,
      "loss": 0.1867,
      "step": 750
    },
    {
      "epoch": 3.04,
      "grad_norm": 0.8995370268821716,
      "learning_rate": 3.65701881954795e-05,
      "loss": 0.12,
      "step": 760
    },
    {
      "epoch": 3.08,
      "grad_norm": 0.8406460285186768,
      "learning_rate": 3.6202190090370944e-05,
      "loss": 0.108,
      "step": 770
    },
    {
      "epoch": 3.12,
      "grad_norm": 1.0191528797149658,
      "learning_rate": 3.5831129418344845e-05,
      "loss": 0.1141,
      "step": 780
    },
    {
      "epoch": 3.16,
      "grad_norm": 0.96075040102005,
      "learning_rate": 3.545710762368392e-05,
      "loss": 0.0964,
      "step": 790
    },
    {
      "epoch": 3.2,
      "grad_norm": 1.268690586090088,
      "learning_rate": 3.508022696021226e-05,
      "loss": 0.1019,
      "step": 800
    },
    {
      "epoch": 3.24,
      "grad_norm": 1.4675694704055786,
      "learning_rate": 3.470059046334011e-05,
      "loss": 0.1037,
      "step": 810
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 1.2453360557556152,
      "learning_rate": 3.4318301921895084e-05,
      "loss": 0.1034,
      "step": 820
    },
    {
      "epoch": 3.32,
      "grad_norm": 1.1272329092025757,
      "learning_rate": 3.3933465849747275e-05,
      "loss": 0.1023,
      "step": 830
    },
    {
      "epoch": 3.36,
      "grad_norm": 0.9206942915916443,
      "learning_rate": 3.3546187457236244e-05,
      "loss": 0.095,
      "step": 840
    },
    {
      "epoch": 3.4,
      "grad_norm": 1.3786072731018066,
      "learning_rate": 3.3156572622407565e-05,
      "loss": 0.1119,
      "step": 850
    },
    {
      "epoch": 3.44,
      "grad_norm": 1.4602086544036865,
      "learning_rate": 3.276472786206679e-05,
      "loss": 0.1046,
      "step": 860
    },
    {
      "epoch": 3.48,
      "grad_norm": 1.5256128311157227,
      "learning_rate": 3.237076030265884e-05,
      "loss": 0.103,
      "step": 870
    },
    {
      "epoch": 3.52,
      "grad_norm": 0.9745686054229736,
      "learning_rate": 3.1974777650980735e-05,
      "loss": 0.1079,
      "step": 880
    },
    {
      "epoch": 3.56,
      "grad_norm": 1.0192201137542725,
      "learning_rate": 3.1576888164735575e-05,
      "loss": 0.0976,
      "step": 890
    },
    {
      "epoch": 3.6,
      "grad_norm": 1.0333867073059082,
      "learning_rate": 3.117720062293599e-05,
      "loss": 0.135,
      "step": 900
    },
    {
      "epoch": 3.64,
      "grad_norm": 1.0376434326171875,
      "learning_rate": 3.077582429616506e-05,
      "loss": 0.0971,
      "step": 910
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.712266206741333,
      "learning_rate": 3.037286891670281e-05,
      "loss": 0.1223,
      "step": 920
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 1.3432800769805908,
      "learning_rate": 2.9968444648526493e-05,
      "loss": 0.1039,
      "step": 930
    },
    {
      "epoch": 3.76,
      "grad_norm": 1.275056004524231,
      "learning_rate": 2.956266205719288e-05,
      "loss": 0.0994,
      "step": 940
    },
    {
      "epoch": 3.8,
      "grad_norm": 1.353596568107605,
      "learning_rate": 2.915563207961074e-05,
      "loss": 0.1049,
      "step": 950
    },
    {
      "epoch": 3.84,
      "grad_norm": 1.2381914854049683,
      "learning_rate": 2.874746599371175e-05,
      "loss": 0.1066,
      "step": 960
    },
    {
      "epoch": 3.88,
      "grad_norm": 1.1564563512802124,
      "learning_rate": 2.8338275388028295e-05,
      "loss": 0.1001,
      "step": 970
    },
    {
      "epoch": 3.92,
      "grad_norm": 1.2877193689346313,
      "learning_rate": 2.792817213118623e-05,
      "loss": 0.0928,
      "step": 980
    },
    {
      "epoch": 3.96,
      "grad_norm": 1.3204147815704346,
      "learning_rate": 2.7517268341321112e-05,
      "loss": 0.1176,
      "step": 990
    },
    {
      "epoch": 4.0,
      "grad_norm": 1.4154099225997925,
      "learning_rate": 2.7105676355426248e-05,
      "loss": 0.1124,
      "step": 1000
    }
  ],
  "logging_steps": 10,
  "max_steps": 2000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 8,
  "save_steps": 250,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.259895271789691e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
